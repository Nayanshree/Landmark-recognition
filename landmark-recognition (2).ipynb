{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U efficientnet","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nRequirement already satisfied, skipping upgrade: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.16.2)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 1.5 MB/s eta 0:00:011\n\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.4.1)\nRequirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.2.1)\nRequirement already satisfied, skipping upgrade: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.4)\nRequirement already satisfied, skipping upgrade: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (8.0.0)\nRequirement already satisfied, skipping upgrade: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.8.0)\nRequirement already satisfied, skipping upgrade: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.1.1)\nRequirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.10.0)\nRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.18.5)\nRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.1)\nRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.4.7)\nRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.0)\nRequirement already satisfied, skipping upgrade: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.10.0)\nRequirement already satisfied, skipping upgrade: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet) (4.4.2)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.14.0)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport re\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import MobileNetV2\nfrom keras.utils import to_categorical\nfrom keras.layers import Dense\nfrom keras import Model\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom tensorflow.keras.applications.xception import Xception\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\n\nimport tensorflow.keras.layers as L\nimport efficientnet.tfkeras as efn","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/landmark-recognition-2020/train.csv\")\ntrain_images = glob.glob('../input/landmark-recognition-2020/train/*/*/*/*')\ntest_images = glob.glob('../input/landmark-recognition-2020/test/*/*/*/*')\nsample = pd.read_csv(\"../input/landmark-recognition-2020/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['landmark_id'].value_counts() # counting landmark classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['id'].value_counts()# Checking if all the ids are distinct","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for Duplicates\ntrain_data.duplicated().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Labelling train image paths with landmark id from the current train csv file"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dict of image id and landmark id\nimage_id = {}\nfor i in range(len(train_data)):\n    x = train_data['id'][i]\n    image_id[x] = train_data['landmark_id'][i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a dataframe with landmark id and train image path\nimport re\ndict_image_target = {}\nfor i in range(len(train_images)):\n    x = re.findall(r'/[0-9A-Za-z]/[0-9A-Za-z]/[0-9A-Za-z]/(.*).jpg',train_images[i])\n    dict_image_target[train_images[i]] = image_id[x[0]]\ndf_images_train = pd.DataFrame(list(dict_image_target.items()), columns=['Image_path','Target'])    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_images_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating dataframe for the test image path\ndf_images_test = pd.DataFrame(test_images, columns = ['Image_path']) \ndf_images_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performing basic visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Density plot to show distribution of classes\nplt.figure(figsize = (12, 8))\n\n\nsns.kdeplot(df_images_train['Target'], color=\"yellow\",shade=True)\nplt.xlabel(\"LandMark IDs\")\nplt.ylabel(\"Probability Density\")\nplt.title('Class Distribution - Density plot')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 10 most frequently occurring landmarks\nfig = plt.figure(figsize = (12,8))\n\ncount = train_data.landmark_id.value_counts().sort_values(ascending=False)[:10]\n\nsns.countplot(x=train_data.landmark_id,\n             order = train_data.landmark_id.value_counts().sort_values(ascending=False).iloc[:10].index)\n\nplt.xticks(rotation = 90)\n\nplt.xlabel(\"LandMark Id\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Top 10 Classes in the Dataset\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top five images in the dataset\nhead_5 = train_data.landmark_id.value_counts().sort_values(ascending=False)[:5].index\n\nimages = []\n\nfor i in range(5):\n    img=cv2.imread(df_images_train[df_images_train.Target == head_5[i]]['Image_path'].values[1])   \n    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    images.append(image)\n\nf, ax = plt.subplots(3,2, figsize=(20,15))\nfor i, img in enumerate(images):        \n        ax[i//2, i%2].imshow(img)\n        ax[i//2, i%2].axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some images from the test dataset\ntest_images = df_images_test.Image_path[1:13]\nimages = []\n\nfor i in range(1,13):\n    img=cv2.imread(test_images[i])   \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    images.append(img)\nf, ax = plt.subplots(3,4, figsize=(20,15))\nfor i, img in enumerate(images):\n        ax[i//4, i%4].imshow(img)\n        ax[i//4, i%4].axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_rate = 0.2 # 20% validation dataset\nbatch_size = 5 # Batch size kept small in order to process the epochs faster","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_images_train['Target'] = df_images_train['Target'].astype(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image pre-processing\ngen = ImageDataGenerator(validation_split=val_rate)\n\ntrain_gen = gen.flow_from_dataframe(\n    df_images_train,\n    directory=\"\",\n    x_col=\"Image_path\",\n    y_col=\"Target\",\n    weight_col=None,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=\"categorical\",\n    batch_size=batch_size,\n    shuffle=True,\n    subset=\"training\",\n    interpolation=\"nearest\",\n    validate_filenames=False)\n\nval_gen = gen.flow_from_dataframe(\n    df_images_train,\n    directory=\"\",\n    x_col=\"Image_path\",\n    y_col=\"Target\",\n    weight_col=None,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=\"categorical\",\n    batch_size=batch_size,\n    shuffle=True,\n    subset=\"validation\",\n    interpolation=\"nearest\",\n    validate_filenames=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    efn.EfficientNetB2(\n        input_shape=(256, 256, 3),\n        weights='imagenet',\n        include_top=False\n    ),\n    L.GlobalAveragePooling2D(),\n    L.Dense(81313, activation='softmax')\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training parameters\nepochs = 1 # maximum number of epochs\ntrain_steps = int(len(df_images_train)*(1-val_rate))//batch_size # Tuning parameter\nval_steps = int(len(df_images_train)*val_rate)//batch_size\n\nmodel_checkpoint = ModelCheckpoint(\"model_efnB3.h5\", save_best_only=True, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_gen, steps_per_epoch=train_steps, epochs=epochs,validation_data=val_gen, validation_steps=val_steps, callbacks=[model_checkpoint])\n\nmodel.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stored_model = load_model(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen = ImageDataGenerator().flow_from_dataframe(\n    df_images_test,\n    directory=\"../input/landmark-recognition-2020/test/\",\n    x_col=\"filename\",\n    y_col=None,\n    weight_col=None,\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    classes=None,\n    class_mode=None,\n    batch_size=1,\n    shuffle=True,\n    subset=None,\n    interpolation=\"nearest\",\n    validate_filenames=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_mod = stored_model.predict_generator(test_gen, verbose=1, steps = test_steps)\n\ny_pred = np.argmax(y_pred_oh, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}